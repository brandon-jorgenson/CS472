{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. (40%) Correctly implement the ID3 decision tree algorithm, including the ability to handle unknown attributes (You do not need to handle real valued attributes).  \n",
    "### Code Requirements/Notes:\n",
    "- Use standard information gain as your basic attribute evaluation metric.  (Note that normal ID3 would usually augment information gain with gain ratio or some other mechanism to penalize statistically insignificant attribute splits. Otherwise, even with approaches like pruning below, the SSE type of overfit could still hurt us.) \n",
    "- You are welcome to create other classes and/or functions in addition to the ones provided below. (e.g. If you build out a tree structure, you might create a node class).\n",
    "- It is a good idea to use a simple data set (like the lenses data or the pizza homework), which you can check by hand, to test your algorithm to make sure that it is working correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DTClassifier(BaseEstimator,ClassifierMixin):\n",
    "    \n",
    "    def __init__(self, feature_names=None):\n",
    "        self.feature_names = feature_names\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.split_gains = np.array([])\n",
    "        self.tree = self.make_tree(X, y, self.feature_names)\n",
    "        return self\n",
    "    \n",
    "    def make_tree(self, X, y, feature_names):\n",
    "        totalEntropy = self.entropy(y, 1)\n",
    "\n",
    "        if len(X) == 0 or len(X[0]) == 0:\n",
    "            values, counts = np.unique(y, return_counts=True)\n",
    "            return values[np.argmax(counts)]\n",
    "        elif (y == y[0]).sum() == len(X):\n",
    "            if isinstance(y[0], (int, np.integer)) or isinstance(y[0], np.str_):\n",
    "                return y[0]\n",
    "            else:\n",
    "                return y[0][0]\n",
    "        else:\n",
    "            info_gain = self.calc_info_gain(X, y)\n",
    "            gain = np.absolute(info_gain - totalEntropy)\n",
    "            best_feature = np.argmax(gain)\n",
    "            self.split_gains = np.append(self.split_gains, gain[best_feature])\n",
    "            tree = {feature_names[best_feature]:{}}\n",
    "            values = []\n",
    "            for row in X:\n",
    "                if row[best_feature] not in values:\n",
    "                    values.append(row[best_feature])\n",
    "            for value in values:\n",
    "                new_X = []\n",
    "                new_y = []\n",
    "                index = 0\n",
    "                for row in X:\n",
    "                    if row[best_feature]==value:\n",
    "                        if best_feature == 0:\n",
    "                            new_row = row[1:]\n",
    "                            new_feature_names = feature_names[1:]\n",
    "                        elif best_feature == len(X[0]):\n",
    "                            new_row = row[:-1]\n",
    "                            new_feature_names = feature_names[:-1]\n",
    "                        else:\n",
    "                            new_row = row[:best_feature]\n",
    "                            new_row = np.append(new_row, row[best_feature+1:])\n",
    "                            new_feature_names = feature_names[:best_feature]\n",
    "                            new_feature_names = np.append(new_feature_names, feature_names[best_feature+1:])\n",
    "                        new_X.append(new_row)\n",
    "                        new_y.append(y[index])\n",
    "                    index +=1\n",
    "                subtree = self.make_tree(np.array(new_X), np.array(new_y), new_feature_names)\n",
    "                \n",
    "                tree[feature_names[best_feature]][value] = subtree     \n",
    "        return tree\n",
    "    \n",
    "    def calc_info_gain(self, X, y):\n",
    "        \n",
    "        total_info = np.array([])\n",
    "        for column in X.T:\n",
    "            value,counts = np.unique(column, return_counts=True)\n",
    "            feature_info = 0\n",
    "            for indx, i in enumerate(value):\n",
    "                feature_info += dt.entropy(y[column == i], counts[indx]/X.shape[0])\n",
    "            total_info = np.append(total_info, feature_info)\n",
    "        return total_info\n",
    "        \n",
    "        \n",
    "        \n",
    "    def entropy(self, y, attribute_prob):\n",
    "        value,counts = np.unique(y, return_counts=True)\n",
    "        norm_counts = counts / counts.sum()\n",
    "        return -attribute_prob*(norm_counts * np.log(norm_counts)/np.log(2)).sum()\n",
    "    \n",
    "    def print_tree(self, t, s):\n",
    "        if not isinstance(t,dict) and not isinstance(t,list):\n",
    "            print(\"\\t\"*s+str(t))\n",
    "        else:\n",
    "            for key in t:\n",
    "                print(\"\\t\"*s+str(key))\n",
    "                if not isinstance(t,list):\n",
    "                    self.print_tree(t[key],s+1)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        prediction = np.array([])\n",
    "        for row in X:\n",
    "            prediction = np.append(prediction, self.predict_row(self.tree, row))\n",
    "        return prediction, prediction.shape[0]\n",
    "    \n",
    "    def predict_row(self, tree, row):\n",
    "        if type(tree) == type(\"string\") or isinstance(tree, (int, np.integer)):\n",
    "            return tree\n",
    "        else:\n",
    "            key = list(tree)[0]\n",
    "            for i in range(len(self.feature_names)):\n",
    "                if self.feature_names[i] == key:\n",
    "                    break\n",
    "                    \n",
    "            try:\n",
    "                t = tree[key][row[i]]\n",
    "                return self.predict_row(t, row)\n",
    "            except:\n",
    "                return None\n",
    "\n",
    "    def score(self, X, y):\n",
    "        prediction, length = self.predict(X)\n",
    "        correct = 0\n",
    "        #print(prediction)\n",
    "        #print(y)\n",
    "        for i in range(length):\n",
    "            if prediction[i] == y[i]:\n",
    "                correct += 1\n",
    "        \n",
    "        return correct/length\n",
    "    \n",
    "def shuffle_data(X, y):\n",
    "    xy = np.column_stack((X,y))\n",
    "    size = xy.shape[0]\n",
    "    for i in range(size):\n",
    "        swapIndex = np.random.randint(0,size)\n",
    "        xy[i], xy[swapIndex] = xy[swapIndex], xy[i].copy()\n",
    "    return xy[:,:-1], xy[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Debug\n",
    "\n",
    "Debug your model by training on the lenses dataset: [Debug Dataset](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/lenses.arff)\n",
    "\n",
    "Test your model on the lenses test set: [Debug Test Dataset](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/lenses_test.arff)\n",
    "\n",
    "Parameters:\n",
    "(optional) counts = [3,2,2,2] (You should compute this when you read in the data, before fitting)\n",
    "\n",
    "---\n",
    "\n",
    "Expected Results: Accuracy = [0.33]\n",
    "\n",
    "Predictions should match this file: [Lenses Predictions](https://raw.githubusercontent.com/cs472ta/CS472/master/debug_solutions/pred_lenses.csv)\n",
    "\n",
    "Split Information Gains (These do not need to be in this exact order):\n",
    "\n",
    "[0.5487949406953987, 0.7704260414863775, 0.3166890883150208, 1.0, 0.4591479170272447, 0.9182958340544894]\n",
    "\n",
    "<!-- You should be able to get about 68% (61%-82%) predictive accuracy on the lenses data -->\n",
    "\n",
    "Here's what your decision tree splits should look like, and the corresponding child node predictions:\n",
    "\n",
    "Decision Tree:\n",
    "<pre>\n",
    "feature_3 = 0:\n",
    "\tfeature_2 = 0:\n",
    "\t\tfeature_0 = 0:\n",
    "\t\t\tprediction: 2\n",
    "\t\tfeature_0 = 1:\n",
    "\t\t\tfeature_1 = 0:\n",
    "\t\t\t\tprediction: 2\n",
    "\t\t\tfeature_1 = 1:\n",
    "\t\t\t\tprediction: 1\n",
    "\t\tfeature_0 = 2:\n",
    "\t\t\tprediction: 2\n",
    "\tfeature_2 = 1:\n",
    "\t\tfeature_1 = 0:\n",
    "\t\t\tfeature_0 = 0:\n",
    "\t\t\t\tprediction: 1\n",
    "\t\t\tfeature_0 = 1:\n",
    "\t\t\t\tprediction: 1\n",
    "\t\t\tfeature_0 = 2:\n",
    "\t\t\t\tprediction: 0\n",
    "\t\tfeature_1 = 1:\n",
    "\t\t\tprediction: 0\n",
    "feature_3 = 1:\n",
    "\tprediction: 1\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DTClassifier(feature_names=array(['Meat', 'Crust', 'Veg'], dtype='<U5'))"
      ]
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Debug on pizza\n",
    "pizza_data = pd.DataFrame({\n",
    "    \"Meat\" : ['Y', 'N', 'N', 'Y', 'Y', 'Y', 'N', 'Y', 'N'],\n",
    "    \"Crust\" : ['Thin', 'Deep', 'Stuffed', 'Stuffed', 'Deep', 'Deep', 'Thin', 'Deep', 'Thin'],\n",
    "    'Veg' : ['N', 'N', 'Y', 'Y', 'N', 'Y', 'Y', 'N', 'N'],\n",
    "    'Quality' : ['Great', 'Bad', 'Good', 'Great', 'Good', 'Great', 'Good', 'Good', 'Bad']\n",
    "})\n",
    "\n",
    "np_data = np.array(pizza_data)\n",
    "\n",
    "X = np_data[:,0:-1]\n",
    "y = np_data[:, -1]\n",
    "\n",
    "dt = DTClassifier(np.array([\"Meat\", \"Crust\", \"Veg\"]))\n",
    "dt.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  2890  100  2890    0     0   7391      0 --:--:-- --:--:-- --:--:--  7391\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  2839  100  2839    0     0  22531      0 --:--:-- --:--:-- --:--:-- 22531\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   144  100   144    0     0    503      0 --:--:-- --:--:-- --:--:--   501\n",
      "0.3333333333333333\n",
      "[0.54879494 0.77042604 0.31668909 1.         0.45914792 0.91829583]\n"
     ]
    }
   ],
   "source": [
    "# Load debug training data \n",
    "!curl https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/lenses.arff --output dataset.arff\n",
    "data = arff.loadarff('dataset.arff')\n",
    "df = pd.DataFrame(data[0])\n",
    "df = df.apply(lambda x: x.str.decode('utf-8'))\n",
    "\n",
    "np_data = np.array(df)\n",
    "X = np_data[:,0:-1]\n",
    "y = np.reshape(np_data[:,-1], (-1, 1))\n",
    "features = np.array(df.columns)\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y)\n",
    "y = le.transform(y)\n",
    "\n",
    "dt = DTClassifier(features)\n",
    "dt = dt.fit(X,y)\n",
    "\n",
    "# Load debug test data\n",
    "!curl https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/lenses_test.arff --output dataset.arff\n",
    "data = arff.loadarff('dataset.arff')\n",
    "df = pd.DataFrame(data[0])\n",
    "df = df.apply(lambda x: x.str.decode('utf-8'))\n",
    "\n",
    "np_data = np.array(df)\n",
    "X = np_data[:,0:-1]\n",
    "y = np.reshape(np_data[:,-1], (-1, 1))\n",
    "y = le.transform(y)\n",
    "\n",
    "!curl https://raw.githubusercontent.com/cs472ta/CS472/master/debug_solutions/pred_lenses.csv --output dataset.csv\n",
    "true_results = genfromtxt('dataset.csv', delimiter=',')\n",
    "# Predict and compute model accuracy\n",
    "print(dt.score(X, y))\n",
    "# Print the information gain of every split you make.\n",
    "print(dt.split_gains)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional/Additional Debugging Dataset - Pizza Homework\n",
    "# pizza_dataset = np.array([[1,2,0],[0,0,0],[0,1,1],[1,1,1],[1,0,0],[1,0,1],[0,2,1],[1,0,0],[0,2,0]])\n",
    "# pizza_labels = np.array([2,0,1,2,1,2,1,1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Evaluation\n",
    "\n",
    "We will evaluate your model based on its performance on the zoo dataset. \n",
    "\n",
    "Train your model using this dataset: [Evaluation Train Dataset](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/zoo.arff)\n",
    "\n",
    "Test your model on this dataset: [Evaluation Test Dataset](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/zoo_test.arff)\n",
    "\n",
    "Parameters:\n",
    "(optional) counts = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 2, 2] (You should compute this when you read in the data, before fitting)\n",
    "\n",
    "---\n",
    "Print out your accuracy on the evaluation test dataset.\n",
    "\n",
    "Print out the information gain of every split you make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  6683  100  6683    0     0  28317      0 --:--:-- --:--:-- --:--:-- 28317\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  171k  100  171k    0     0   410k      0 --:--:-- --:--:-- --:--:--  410k\n",
      "0.147\n",
      "[1.3630469  0.68920199 0.86312057 0.72192809 0.88654089 0.69621226\n",
      " 0.98522814 0.82562653 0.72192809]\n"
     ]
    }
   ],
   "source": [
    "# Load evaluation data \n",
    "!curl https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/zoo.arff --output dataset.arff\n",
    "data = arff.loadarff('dataset.arff')\n",
    "df = pd.DataFrame(data[0])\n",
    "df = df.apply(lambda x: x.str.decode('utf-8'))\n",
    "\n",
    "np_data = np.array(df)\n",
    "X = np_data[:,0:-1]\n",
    "y = np.reshape(np_data[:,-1], (-1, 1))\n",
    "features = np.array(df.columns)\n",
    "dt = DTClassifier(features)\n",
    "dt = dt.fit(X,y)\n",
    "\n",
    "# Load evaluation test data\n",
    "!curl https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/zoo_test.arff --output dataset.arff\n",
    "data = arff.loadarff('dataset.arff')\n",
    "df = pd.DataFrame(data[0])\n",
    "df = df.apply(lambda x: x.str.decode('utf-8'))\n",
    "\n",
    "np_data = np.array(df)\n",
    "X = np_data[:,0:-1]\n",
    "y = np.reshape(np_data[:,-1], (-1, 1))\n",
    "\n",
    "# Print results\n",
    "print(dt.score(X, y))\n",
    "# 0.147\n",
    "print(dt.split_gains)\n",
    "# [1.3630469  0.68920199 0.86312057 0.72192809 0.88654089 0.69621226 0.98522814 0.82562653 0.72192809]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. (20%) You will use your ID3 algorithm to induce decision trees for the cars dataset and the voting dataset.  Do not use a stopping criteria, but induce the tree as far as it can go (until classes are pure or there are no more data or attributes to split on).  \n",
    "- Implement and use 10-fold Cross Validation (CV) on each data set to predict how well the models will do on novel data.  \n",
    "- For each dataset, report the training and test classification accuracy for each fold and the average test accuracy. \n",
    "- As a rough sanity check, typical decision tree accuracies for these data sets are: Cars: .90-.95, Vote: .92-.95."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Implement 10-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function that implements 10-fold cross validation\n",
    "def ten_fold_validation(dt, X, y):\n",
    "    accuracies = np.array([])\n",
    "    X, y = shuffle_data(X,y)\n",
    "    split_X = np.array_split(X,10)\n",
    "    indx = 0\n",
    "    for array in split_X:\n",
    "        X_test = X[indx:indx+array.shape[0], :]\n",
    "        y_test = y[indx:indx+array.shape[0]]\n",
    "        X_train = np.delete(X, np.s_[indx:indx+array.shape[0]],0)\n",
    "        y_train = np.expand_dims(np.delete(y, np.s_[indx:indx+array.shape[0]]), 0).T\n",
    "        dt.fit(X_train, y_train)\n",
    "        accuracies = np.append(accuracies, dt.score(X_test, y_test))\n",
    "        indx += array.shape[0]\n",
    "    return accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2.2 Cars Dataset\n",
    "- Use this [Cars Dataset](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/cars.arff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 55393  100 55393    0     0   365k      0 --:--:-- --:--:-- --:--:--  363k\n",
      "individual accuracies [0.91907514 0.89595376 0.9132948  0.87861272 0.86127168 0.89017341\n",
      " 0.9017341  0.85549133 0.9127907  0.87790698]\n",
      "average accuracy 0.890630461083479\n"
     ]
    }
   ],
   "source": [
    "# Use 10-fold CV on Cars Dataset\n",
    "# Load cars dataset\n",
    "!curl https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/cars.arff --output dataset.arff\n",
    "data = arff.loadarff('dataset.arff')\n",
    "df = pd.DataFrame(data[0])\n",
    "df = df.apply(lambda x: x.str.decode('utf-8'))\n",
    "\n",
    "np_data = np.array(df)\n",
    "X = np_data[:,0:-1]\n",
    "y = np.reshape(np_data[:,-1], (-1, 1))\n",
    "features = np.array(df.columns)\n",
    "dt = DTClassifier(features)\n",
    "accuracies = ten_fold_validation(dt, X, y)\n",
    "print(\"individual accuracies\", accuracies)\n",
    "print(\"average accuracy\", np.average(accuracies))\n",
    "# Accuracies from one run\n",
    "\n",
    "# accuracies [0.89595376 0.89595376 0.9017341  0.9132948  0.90751445 0.92485549\n",
    "# 0.84393064 0.87861272 0.93023256 0.87209302]\n",
    "\n",
    "#average accuracy ~89.6%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Voting Dataset\n",
    "- Use this [Voting Dataset with missing values](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/voting_with_missing.arff)\n",
    "- Note that you will need to support unknown attributes in the voting data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 40261  100 40261    0     0   295k      0 --:--:-- --:--:-- --:--:--  293k\n",
      "individual accuracies [0.93181818 0.93181818 0.93181818 0.95454545 0.93181818 0.93023256\n",
      " 0.93023256 0.93023256 0.97674419 0.93023256]\n",
      "average accuracy 0.9379492600422832\n"
     ]
    }
   ],
   "source": [
    "# Used 10-fold CV on Voting Dataset\n",
    "!curl https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/voting_with_missing.arff --output dataset.arff\n",
    "data = arff.loadarff('dataset.arff')\n",
    "df = pd.DataFrame(data[0])\n",
    "df = df.apply(lambda x: x.str.decode('utf-8'))\n",
    "\n",
    "np_data = np.array(df)\n",
    "X = np_data[:,0:-1]\n",
    "y = np.reshape(np_data[:,-1], (-1, 1))\n",
    "features = np.array(df.columns)\n",
    "dt = DTClassifier(features)\n",
    "accuracies = ten_fold_validation(dt, X, y)\n",
    "print(\"individual accuracies\", accuracies)\n",
    "print(\"average accuracy\", np.average(accuracies))\n",
    "# Report Training and Test Classification Accuracies\n",
    "\n",
    "# individual accuracies [0.95454545 0.93181818 0.86363636 0.93181818 0.97727273 0.97674419\n",
    "# 0.95348837 0.90697674 0.93023256 0.97674419]\n",
    "\n",
    "# Report Average Test Accuracy\n",
    "#average accuracy ~94.0%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Discuss Your Results\n",
    "\n",
    "- Summarize your results from both datasets, and discuss what you observed. \n",
    "- A fully expanded tree will often get 100% accuracy on the training set. Why does this happen and in what cases might it not?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was able to get close to 90% accuracy on the cars dataset and 93-94% accuracy on the voting dataset.\n",
    "I have added my individual and average accuracies from doing the ten fold validation in the cells above.\n",
    "\n",
    "A fully expanded tree can get to 100% accuracy on the training set because it can overfit. If the training set contains pure nodes when you split on all of the features because of low data, you can fit to that and get that accuracy on the training set but it might not be performant on real-world data.\n",
    "\n",
    "It might not get to 100% if you have rows with very similar data with different targets. Then you end up choosing the most common one, which will not be accurate for the remainding data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. (15%) For each of the two problems above, summarize in English what the decision tree has learned (i.e. look at the induced tree and describe what rules it has discovered to try to solve each task). \n",
    "- If the tree is very large you can just discuss a few of the more shallow attribute combinations and the most important decisions made high in the tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Discuss what the decision tree induced on the cars dataset has learned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tree uses safety as its starting point. If the safety is low, we already know that the car in unacceptable. \n",
    "At the next layer down after splitting on med and high safety, if the car only has the capacity for two persons, it is also unacceptable. The next biggest attributes to split on are capacity, buying cost, and maintenance cost.\n",
    "\n",
    "As you go down the tree it gets more complicated, but here are a few gneral observations:\n",
    "    If a 4 person car's cost is low and maintenance is not very high, it is probably at least acceptable.\n",
    "    A high buying cost is fine if the maintenance is lower than high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Discuss what the decision tree induced on the voting dataset has learned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important decision in the voting preference on physician-fee-freeze. The unknown value is helpful here because an unknown vote can quickly predict the political party based on the mx-missle and anti-satellite-test-ban\n",
    "votes.\n",
    "\n",
    "Going down the other paths takes a few vote splits to start predicting the output class.\n",
    "If no on the physician-fee-freeze,it can predict on y or ? of the adoption-of-the-budget-resolution vote, otherwise it goes down to education spending and so on.\n",
    "\n",
    "With a yes on physician-fee-freeze, the tree splits on synfuels-corporation-cutback, then export-administration-act-south-africa and adoption-of-the-budget-resolution.It can predict republican on a n or y on the export vote, otherwise it needs to go down deeper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 How did you handle unknown attributes in the voting problem? Why did you choose this approach? (Do not use the approach of just throwing out data with unknown attributes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I treated unknown attritutes as their own value type because the unknown classification in this dataset \n",
    "did not mean that the voting outcome was necessarily unknown. It signified voted present, voted\n",
    "present to avoid conflict of interest, and did not vote or unknown disposition. This might actually \n",
    "be valuable when predicting the target, so I kept the values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 (10%) Use SciKit Learn's decision tree on the voting dataset and compare your results. Try different parameters and report what parameters perform the best on the test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 SK Learn on Voting Dataset\n",
    "- Use this [Voting Dataset with missing values](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/voting_with_missing.arff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 40261  100 40261    0     0   126k      0 --:--:-- --:--:-- --:--:--  126k\n",
      "individual accuracies [0.97727273 0.97727273 0.97727273 0.93181818 1.         0.93023256\n",
      " 1.         0.90697674 0.90697674 0.95348837]\n",
      "average accuracy 0.9561310782241014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brandon/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Use SK Learn's Decision Tree to learn the voting dataset\n",
    "!curl https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/voting_with_missing.arff --output dataset.arff\n",
    "data = arff.loadarff('dataset.arff')\n",
    "df = pd.DataFrame(data[0])\n",
    "df = df.apply(lambda x: x.str.decode('utf-8'))\n",
    "np_data = np.array(df)\n",
    "X = np_data[:,0:-1]\n",
    "y = np.reshape(np_data[:,-1], (-1, 1))\n",
    "features = np.array(df.columns)\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y)\n",
    "y = le.transform(y)\n",
    "\n",
    "indx = 0\n",
    "for col in X.T:\n",
    "    le.fit(col)\n",
    "    X[:, indx] = le.transform(col)\n",
    "    indx += 1\n",
    "\n",
    "clf = DecisionTreeClassifier(criterion='gini', min_samples_split=16)\n",
    "clf.fit(X,y)\n",
    "#ten_fold_validation(clf, X, y)\n",
    "accuracies = cross_val_score(clf, X, y.ravel(), cv=10)\n",
    "print(\"individual accuracies\", accuracies)\n",
    "print(\"average accuracy\", np.average(accuracies))\n",
    "# Explore different parameters\n",
    "\n",
    "# Report results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the default DecisionTreeClassifier I got around 94% accuracy. I was able to bump it up to 95.6% by\n",
    "increasing min samples split to 16. The other parameters I tried such as criterion, splitter, max_depth, and min samples leaf didn't change much or decreased the accuracy.\n",
    "\n",
    "My own decision tree was slightly less accurate, usually averaging around 93-94% accuracy, but if I tuned my own to work with these parameters I would probably get about the same accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 (10%) Choose a data set of your choice (not already used in this or previous labs) and use the SK decision tree to learn it. Experiment with different hyper-parameters to try to get the best results possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average accuracy 0.8585034013605443\n"
     ]
    }
   ],
   "source": [
    "# Use SciKit Learn's Decision Tree on a new dataset\n",
    "notebook_path = os.path.abspath(\"lab_3_decision_tree.ipynb\")\n",
    "train_csv = os.path.join(os.path.dirname(notebook_path), \"Employee-Attrition.csv\")\n",
    "df=pd.read_csv(train_csv, sep=',',header=None)\n",
    "np_data = np.array(df)\n",
    "\n",
    "X = np_data[1:,0:-1]\n",
    "y = np.reshape(np_data[1:,-1], (-1, 1))\n",
    "\n",
    "indx = 0\n",
    "for col in X.T:\n",
    "    le.fit(col)\n",
    "    X[:, indx] = le.transform(col)\n",
    "    indx += 1\n",
    "clf = DecisionTreeClassifier(criterion=\"entropy\", min_samples_split=100, min_samples_leaf=20)\n",
    "#clf = DecisionTreeClassifier()\n",
    "clf.fit(X,y)\n",
    "accuracies = cross_val_score(clf, X, y.ravel(), cv=10)\n",
    "print(\"average accuracy\", np.average(accuracies))\n",
    "\n",
    "# I used the Predicting Employee Attrition dataset found on Kaggle\n",
    "\n",
    "# I was able to increase the average accuracy of the Decision tree from 76.59% to 85.85% by changing the\n",
    "# criterion to entropy, the min samples to split on to 100 and the min samples for a leaf to 20.\n",
    "# The other values I experimented with decreased the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. (5%) Visualize your decision tree for your chosen data set (using export_graphviz or another tool) and discuss what you find. If your tree is too deep to reasonably fit on one page, show only the first several levels (e.g. top 5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include decision tree visualization here\n",
    "#with open(\"clf.dot\", \"w\") as f:\n",
    "#    f = tree.export_graphviz(clf, out_file=f, max_depth=3)\n",
    "\n",
    "#                              Overtime\n",
    "#                       True           False\n",
    "#                Total Working Years <=1.5    Job Level <= .5\n",
    "#            True         False                        True                  False\n",
    "#        No Attrition     StockOptionLevel <= .5    Monthly Income <=462        JobRole <6.5\n",
    "#                                                   No Attrition   Attrition\n",
    "\n",
    "    \n",
    "# Discuss what the model has learned\n",
    "\n",
    "# The model has learned that the best indicators for predicting employee attrition. The best indicator is\n",
    "# whether or not someone does overtime. Total working years, Job level, job role, stock option level, \n",
    "# and monthly income are also important.\n",
    "# An easy prediction is that if someone is working overtime and has worked at the firm for less than two years,\n",
    "# they are likely to stay with the company. \n",
    "\n",
    "\n",
    "# I only included the top of the tree because it was so large, and I made\n",
    "# a pdf with export graph viz but I don't think I can imbed it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. (optional 5% extra credit) Implement reduced error pruning to help avoid overfitting.  \n",
    "- You will need to take a validation set out of your training data to do this, while still having a test set to test your final accuracy. \n",
    "- Create a table comparing your decision tree implementation's results on the cars and voting data sets with and without reduced error pruning. \n",
    "- This table should compare:\n",
    "    - a) The # of nodes (including leaf nodes) and tree depth of the final decision trees \n",
    "    - b) The generalization (test set) accuracy. (For the unpruned 10-fold CV models, just use their average values in the table)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
